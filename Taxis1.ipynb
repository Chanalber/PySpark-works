{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fec2a1d-3ea1-48ae-9944-2f9ba41818c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2021-11-30 11:00:53,834 WARN util.Utils: Service 'SparkUI' could not bind on port 4064. Attempting port 4065.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/software/spark-3.1.2-bin-hadoop3.2/\"\n",
    "os.environ[\"HADOOP_CONF_DIR\"] = \"/usr/local/hadoop/etc/hadoop/\"\n",
    "os.environ[\"PYSPARK_PYTHON\"]= \"python3.9\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"python3.9\"\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "\n",
    "conf = SparkConf().setAll([('spark.app.name', 'Trabajo_taxis_1'), \\\n",
    "                           ('spark.executor.memory', '1g'), \\\n",
    "                           ('spark.executor.instances','2'), \\\n",
    "                           ('spark.executor.cores', '2'), \\\n",
    "                           ('spark.ui.port', '4064'), \\\n",
    "                           ('spark.driver.memory','1g')])\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).master('yarn').getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "472d0ffe-830e-44bc-89fc-f2bd824a63df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put: `tripdata_2017-01.csv': File exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#tomamos el fichero con un put lo llevamos a hdfs. luego leemos el fichero en python-spark\n",
    "\n",
    "!/usr/local/hadoop/bin/hdfs dfs -put tripdata_2017-01.csv\n",
    "df = spark.read.csv('tripdata_2017-01.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e19746-a5fd-41ca-9347-aecfbcf6743f",
   "metadata": {},
   "source": [
    "PROBLEMA 1: Cantidad de datos procesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4919121-f9d9-48f6-ab86-ee95b7b1ac61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "971010"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count() # cuenta el numero de filas del dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9babcab6-290a-42a7-ae5f-f79ff711ce3f",
   "metadata": {},
   "source": [
    "PROBLEMA 2: Esquema de datos del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4618ce10-6da6-4f2b-8d49-2ac2fef4f472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema() # conocer el tipo de las instancias de cada columna y si pueden ser nulas o no"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b18ed93-ac3d-488d-a84b-f28be4b9a9b2",
   "metadata": {},
   "source": [
    "PROBLEMA 3: Valores max/media/min de cada una de las columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59f00897-02cb-46bc-b8bf-c7e7d4f2e7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+--------------------+---------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+------------------+-------------------+-------------------+------------------+------------------+---------------------+------------------+\n",
      "|summary|           VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|   passenger_count|    trip_distance|        RatecodeID|store_and_fwd_flag|      PULocationID|     DOLocationID|      payment_type|       fare_amount|              extra|            mta_tax|        tip_amount|      tolls_amount|improvement_surcharge|      total_amount|\n",
      "+-------+-------------------+--------------------+---------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+------------------+-------------------+-------------------+------------------+------------------+---------------------+------------------+\n",
      "|  count|             971010|              971010|               971010|            971010|           971010|            971010|            971010|            971010|           971010|            971010|            971010|             971010|             971010|            971010|            971010|               971010|            971010|\n",
      "|   mean| 1.5569510097733288|                null|                 null|1.6859888157691476|3.031284878631562|1.0447286845655555|              null|160.37803112223355|158.5567120832947|1.3719735121162502|13.108188154601887|0.20999277041431086| 0.4972142408420099|1.6790282695338832|0.2801808838220069|  0.29962863410400153|16.078110822714912|\n",
      "| stddev|0.49674624971879017|                null|                 null|1.2917046837574115|3.785847233211705|0.4616312653743067|              null| 67.93819834229261|72.27682104933929|0.5033263270235158|    546.7369331191| 0.2616340036820108|0.04058594644609179|2.5713641104199647| 1.736907713656941| 0.014468410899185439| 546.7901022658552|\n",
      "|    min|                  1| 2017-01-01 00:00:00|  2017-01-01 00:00:00|                 0|              0.0|                 1|                 N|                 1|                1|                 1|            -120.0|               -1.0|               -0.5|             -6.06|               0.0|                 -0.3|            -120.3|\n",
      "|    max|                  2| 2017-01-31 15:41:14|  2017-01-31 16:02:32|                 9|            151.7|                99|                 Y|               265|              265|                 4|          538579.2|              55.54|                0.5|             366.0|            905.54|                  0.3|          538580.0|\n",
      "+-------+-------------------+--------------------+---------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+------------------+-------------------+-------------------+------------------+------------------+---------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe().show() # te muestra numero de filas, media, minimo y maximo de las columnas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
